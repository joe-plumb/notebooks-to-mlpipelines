{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries \n",
    "\n",
    "Any libraries that are required for the data prep step should be imported in the next cell. This ensures that the created py script for our pipeline conforms to [PEP8 styling guide best practice](https://www.python.org/dev/peps/pep-0008/#imports)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import tempfile\n",
    "import os\n",
    "import logging\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "from azureml.core import Dataset, Workspace, Datastore\n",
    "from azureml.data import TabularDataset, FileDataset\n",
    "from azureml.core.run import _OfflineRun, Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting script parameters with argparse\n",
    "\n",
    "Any parameters such as dataset name or output folder name should be defined using argparse. This is in general good practice and will also make the transition to pipelines more seamless. The default value used should be what you want to use in this notebook, for example if we are wanting to prepare a registered dataset called 'my_raw_data' then you would use:\n",
    "\n",
    "```\n",
    "parser.add_argument(\"--dataset_name1\", default=\"my_raw_data\")\n",
    "```\n",
    "\n",
    "If you have more than one dataset than the one provided below then you can add additional arguments. Moreover, if you want to have a variable with better semantic meaning (e.g. sales_dataset) then feel free to change it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--training_data\",\n",
    "                    type=str,\n",
    "                    default=\"../01-data-prep/outputs/training_data.csv\",\n",
    "                    help=\"file path for \")\n",
    "parser.add_argument(\"--param1\",\n",
    "                    type=float,\n",
    "                    default=1.00,\n",
    "                    help=\"a parameter for an ML model\")\n",
    "\n",
    "args, _ = parser.parse_known_args()\n",
    "\n",
    "training_data = args.training_data\n",
    "output_folder = \".outputs\"\n",
    "param1 = args.param1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write your training code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output model artefacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# below you should write your training sets (or any other data required for training) into the folder created above e.g.\n",
    "# model_path = os.path.join(output_folder, 'model.pkl')\n",
    "# model.save('model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
